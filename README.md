# English dialect classification
This project focuses on the classification of the English language according to the chosen dialects. 
Project made for a course name I don't remember :d. All results and images are in the notebook file.
Made by me, Katia Kolos, Julie Nguyen and Oscar Moreno Escobar. 

Professor: Alice Missud

RÃ©sumÃ©
---
Ce dossier porte toute son attention sur la classification de la langue anglaise selon les dialectes choisis. Afin de vÃ©rifier Ã  quel point la machine est en capacitÃ© de reconnaÃ®tre le dialecte correspondant, on dÃ©cide de prendre en compte des traits lexicaux propres Ã  chacun. La partie syntaxe nâ€™a pas Ã©tÃ© retenue comme candidat suffisant en vue de la forte standardisation de la langue Anglaise comme langue universelle. Aussi, diffÃ©rentes mÃ©thodes de classification ont Ã©tÃ© retenues pour la complÃ©tion de ce projet. On garde 6 types de classifieurs capables dâ€™apprendre Ã  la machine. Une comparaison et une analyse de chacun des rÃ©sultats ont Ã©tÃ© effectuÃ©es, ce qui nous permet de mieux comprendre les rÃ©sultats obtenus pour la partie Ã©valuation des performances.

Introduction
---
Lâ€™analyse de donnÃ©es est lâ€™un des plus gros enjeux quâ€™il y ait depuis quelques annÃ©es maintenant. Analyser les donnÃ©es dessert un grand nombre de domaines, allant de la satisfaction cliente Ã  la traduction multilingue. Lâ€™une des finalitÃ©s Ã  lâ€™analyse de donnÃ©es serait la classification automatique de donnÃ©es.  Pour ce faire, on utilise bien Ã©videmment des algorithmes qui permettent leur traitement et qui donnent aussi un poids Ã  la sÃ©mantique des donnÃ©es textuelles. Pour ce faire, il nous est disponible de traiter avec Word2Vec, Doc2Vec et diffÃ©rents types de classifieurs (SVM, RandomForest, Logistic Regression, etc.). DiffÃ©rentes faÃ§ons de prendre en compte la sÃ©mantique nous ont Ã©tÃ© prÃ©sentÃ©es afin de mener Ã  bien la classification de donnÃ©es. Pour notre part, nous avons choisi de porter notre projet sur la classification de lâ€™anglais selon sa rÃ©gion Â« parlÃ©/Ã©crite Â». 
Lâ€™anglais est une langue parlÃ©e Ã  lâ€™Ã©chelle internationale, ce qui conduit cette langue Ã  connaÃ®tre des variations dâ€™utilisation selon la rÃ©gion dans laquelle elle est pratiquÃ©e. Il est vrai que cette derniÃ¨re est assez standardisÃ©e, cependant on observe des Â« features Â»  propres aux locuteurs natifs. Certaines variations sonores, un lexique diffÃ©rent et l'orthographe de certains mots diffÃ¨rent. Lâ€™anglais utilisÃ© au Royaume-Uni peut donc se distinguer de lâ€™anglais Â« Ã©tats-unien Â», de lâ€™anglais canadien ou encore australien, ou indien.
Ainsi, on cherche Ã  classifier lâ€™anglais selon un certain nombre de critÃ¨res explicitÃ©s plus bas, parmi quatre rÃ©gions, Ã  savoir : Royaume-Uni (UK dans notre projet), Ã‰tats-Unis (US), Canada (CA) et Australie (AUS). 
La complÃ©tion de ce devoir se fait Ã  lâ€™aide des diffÃ©rents articles scientifiques du domaine pour nous guider dans la mÃ©thodologie Ã  suivre et/ou donner un angle dâ€™approche appropriÃ©, des techniques et une rÃ©flexion afin de mener Ã  bien notre projet.
Il sera donc explicitÃ© les parties suivantes, Ã  travers cinq grands axes de lecture :
- Collecte des donnÃ©es, nettoyage 
- Dictionnaire, traits particuliers :
- Traitement avec Word2vec, Doc2vec 
- Classifieur : Binary and multiclass
- Evaluation et Analyse
- Conclusion et perspective

1) Corpus
Constitution du corpus : rÃ©colte des donnÃ©es
Notre corpus se constitue de tweets rÃ©coltÃ©s par lâ€™API de Twitter. Afin de rÃ©colter les tweets, chacun des membres du groupe a fait une demande dâ€™accÃ¨s en tant que compte administrateur / DÃ©veloppeur. Une fois sâ€™Ãªtre inscrit et avoir rempli les formulaires et condition dâ€™utilisation propre Ã  lâ€™API Twitter, diffÃ©rentes clÃ©s sont fournies afin de scrapper le contenu du rÃ©seau en question. Il faudra donc prendre garde Ã  bien les conserver pour pouvoir les utiliser et scrapper avec le code en question.

Une fois lâ€™accÃ¨s autorisÃ©, le scrapping commence. Chacun des dialectes reprÃ©sente dans notre projet les classes. Pour chacune des classes, une liste de Â« users Â» a Ã©tÃ© dÃ©terminÃ© afin de cibler la rÃ©colte sur des tweets spÃ©cifiques.
On dÃ©finit par Â« rÃ©gion Â» une liste de natif de la langue provenant de cette rÃ©gion anglophone. Câ€™est environ une vingtaine de Â« users Â» qui a Ã©tÃ© sÃ©lectionnÃ© puis scrappÃ©. On cherche Ã  cibler des cÃ©lÃ©britÃ©s reprÃ©sentatives.  On trouvera donc une liste composÃ©, respectivement de cÃ©lÃ©britÃ© comme :
*UK : Emma Watson - US : Halsey - CA : Shawn Mendes - AUS : Alex Greenwich (et dâ€™autres bien sÃ»r)

A noter que diffÃ©rents types de cÃ©lÃ©britÃ©s ont Ã©tÃ© retenus pour le scrapping :
On retrouvera des agents propres au monde politique, du sport, cÃ©lÃ©britÃ© (qui regroupe le mannequinat, le chant, la danse, acteurs)  et enfin, le monde journalistique.
Câ€™est un total de 176 535 tweets qui ont pu Ãªtre rÃ©cupÃ©rÃ©s. Une partie sert pour lâ€™apprentissage de la machine, et le reste comme test. 
Nota Bene : Une premiÃ¨re approche fut de prendre en compte les #locations. Ceci Ã©tait un moyen de cibler sur nos dialectes et donc dâ€™avoir un premier tag de ce que nous cherchions. Cette idÃ©e fut vite laissÃ© de cÃ´tÃ© puisque les #location sont un nombre moindre. La rÃ©colte serait donc pauvre et inintÃ©ressante en vue de lâ€™objectif visÃ©. Aussi, le lieu indiquÃ© par le hashtag peut tout aussi bien signifier le lieu auquel le tweet a Ã©tÃ© Ã©crit, ou encore le lieu oÃ¹ rÃ©side actuellement le user qui a tweetÃ©. Avec un tel risque, il nous a semblÃ© plus juste de choisir manuellement un nombre dÃ©fini de personnes reprÃ©sentatives du dialecte. 

Nettoyage, et script utilisÃ©
---
Le corpus Ã©tant composÃ© de tweets, cela implique une Ã©tape crucial dans la rÃ©alisation du projet : le nettoyage de celui-ci. Les tweets prÃ©sentaient essentiellement beaucoup dâ€™hyperliens, de majuscules, caractÃ¨res spÃ©ciaux, mais aussi des emojis.
On remarque aussi que la rÃ©colte de tweets nous amÃ¨ne Ã  scrapper des tweets courts, non pertinents pour lâ€™apprentissage de notre machine via un pipeline. Certains critÃ¨res ont donc Ã©tÃ© avancÃ©s afin dâ€™amÃ©liorer la qualitÃ© de notre corpus. On dÃ©cide de ne pas prendre en compte les retweets, afin de garder les Ã©crits originaux. Dâ€™ailleurs, les tweets courts (en dessous de 3 mots) ne sont pas comptabilisÃ©s.

2) MÃ©thodologie
- Les Ã©tapes avant classifieurs
Comme dit prÃ©cÃ©demment, le but de ce devoir est de classifier un tweet selon une langue et ses quatre dialectes. Pour ce faire, on utilise des classifieurs sur python, afin dâ€™effectuer cette tÃ¢che. Le corpus Ã©tant maintenant disponible, on dÃ©cide de lancer un premier classifieur afin de voir comment ce dernier rÃ©agit Ã  nos donnÃ©es.
Câ€™est le classi
fieur Naives Bayes et CNN qui ont dâ€™abord Ã©tÃ© choisis. Etrangement, CNN ne donne pas de rÃ©sultat, et Naive Bayes nous donne des taux relativement bas. Lâ€™une de nos premiÃ¨res intuitions sur les rÃ©sultats Ã©tait dÃ» au fait que les mots sont justement pris en tant que tel, comme dans un sac de mots, oÃ¹ chacun nâ€™est pas pris selon son contexte mais de faÃ§on verbatim. On se dit donc que le contexte devait forcÃ©ment Ãªtre pris en compte pour de meilleurs rÃ©sultats.
Un autre point crucial auquel nous avons pensÃ© : il serait sÃ»rement nÃ©cessaire de poser un Â« poids Â» sur certains mots selon leur appartenance. Autrement dit, il y aurait certains termes qui porteraient une pondÃ©ration afin quâ€™ils puissent avoir une plus forte chance de tomber selon le terme et le dialecte associÃ© Ã  ce terme.
Ceci Ã©tant dit, il faut mettre en place un systÃ¨me de dictionnaire propre Ã  chaque dialecte. Pour quelle raison ? Lâ€™anglais possÃ¨de une richesse lexicale qui dÃ©pend de sa rÃ©gion. Certains termes ne sâ€™emploient pas de la mÃªme faÃ§on et dâ€™autres n'existent que dans un dialecte prÃ©cis. On trouvera des variations orthographiques pour un mÃªme mot, un vocabulaire diffÃ©rent pour dÃ©signer un mÃªme sens, et d'autres particularitÃ©s langagiÃ¨res propres Ã  cette derniÃ¨re.

Parmi les exemples que lâ€™on peut citer, on remarque que lâ€™anglais du Royaume Uni utilise le mot Â« cancelled Â» mais Â« canceled Â» en anglais Ã©tats-unien. On pourrait aussi penser Ã  toutes les variations possibles pour dÃ©signer les Â« toilettes Â» : â€˜toiletsâ€™ (UK), â€˜Restroomâ€™ (US), â€˜Bathroomâ€™ (CA), â€˜Washroomâ€™ (AUS).
Ainsi, lâ€™idÃ©e est la suivante : on dÃ©cide de dÃ©finir â€˜toiletsâ€™ comme faisant partie du dictionnaire de UK. De la sorte, si â€˜toiletsâ€™ apparaÃ®t dans le corpus, il aura un poids plus consÃ©quent que les autres termes avoisinants, et sera Â« dâ€™emblÃ©e Â» associÃ© Ã  la classe UK. On rÃ©pÃ¨te cette opÃ©ration sur tous les termes propres Ã  la classe UK, et faisons de mÃªme avec les autres classes et leurs lexiques spÃ©cifiques.

Finalement, nous prÃ©fÃ©rons garder deux dictionnaires propres Ã  deux classes, celui de la classe UK et la classe US. Nous dÃ©cidons de laisser de cÃ´tÃ© les dictionnaires de la classe Canada et Australie. Le problÃ¨me Ã©tant que ces derniÃ¨res nâ€™ont pas un dictionnaire aussi fourni comparÃ© Ã  la classe UK et US. Il ne nous semblait pas intÃ©ressant dâ€™avoir des dictionnaires dÃ©sÃ©quilibrÃ©s en termes de nombres. On espÃ¨re que la pondÃ©ration ajoutÃ©e pour les mots propres aux classes UK et US prendront plus de poids afin dâ€™Ãªtre identifiÃ©e et si non, quâ€™ils seront soit dans la classe CA, soit AUS.

Aussi, peut-on ajouter que nous avions eu une intuition sur le fait de garder ou non les Ã©mojis. Pour quelles raisons ? DÃ©cider de garder les emojis au sein des tweets, se fait pour la simple et bonne raison que nous pourrions certainement dÃ©terminer si un emoji Ã©tait privilÃ©giÃ© dans un dialecte plutÃ´t quâ€™un autre. Prenons comme exemple lâ€™Ã©moji qui suit : ğŸ™ğŸ»

Pour la plupart des pays, cet Ã©moji a pour trait de correspondre Ã  lâ€™innocence, parfois avec ironie certes mais, il peut aussi Ãªtre compris comme une priÃ¨re, ou bien reprÃ©senter une bÃ©nÃ©diction. Ceci est notamment visible aux Etats-Unis et en AmÃ©rique Latine, oÃ¹ le ğŸ™ğŸ» reprÃ©sente Â« le fait de faire le bien autour de soi Â». En Chine en revanche, celui-ci signifie la mort et peut Ãªtre perÃ§u comme une menace voilÃ©e. 

(cf. : <https://www.google.com/amp/s/www.feminactu.com/2020/07/attention-la-signification-des-emojis-peut-varier-dun-pays-a-un-autre/amp/>)

On prend donc en compte les dictionnaires et considÃ©rons dans un premier temps la suppression des Ã©mojis mais aussi un essai en leur prÃ©sence dans notre corpus. Et pour avoir une meilleure visibilitÃ© de ce quâ€™il se passe, câ€™est avec plusieurs classifieurs que lâ€™on soumet notre corpus. Une bonne approche serait le processus suivant :
Notre corpus sert de base dâ€™apprentissage Ã  la machine afin que le classifieur sache ce quâ€™il faut apprendre et/ou relever. Pour se faire, on divise pour chacun des classifieurs les donnÃ©es de notre corpus en deux parties : une premiÃ¨re partie Ã  60% et une deuxiÃ¨me partie Ã  40%. La partie Ã  60% sera utilisÃ©e comme apprentissage et les 40%, seront pour le test. 

Enfin, on soumet les diffÃ©rentes parties des donnÃ©es au classifieur et une fois quâ€™il est soumis, nous utilisons des mÃ©triques afin dâ€™Ã©valuer les performances du classifieur. On affichera les mesures de rappels, de prÃ©cision et de recall en plus de matrices de confusion.

Il ne faut pas oublier quâ€™afin dâ€™avoir une classification qui prend en compte le sens dâ€™un mot, il faut lui donner une reprÃ©sentation vectorielle et commencer par de la classification binaire entre toutes nos classes. Cela permet dâ€™avoir une premiÃ¨re idÃ©e de ce quâ€™il se passe.

- La reprÃ©sentation vectorielle des donnÃ©es

Les plongements lexicaux ont Ã©tÃ© obtenus Ã  lâ€™aide de la bibliothÃ¨que gensim. Nous avons dÃ©cidÃ© de faire 3 types de vecteurs : un Doc2Vec, un Word2Vec.  Quatre modÃ¨les ont Ã©tÃ© utilisÃ©s. Dâ€™un cÃ´tÃ©, un Doc2Vec et un Word2Vec avec la version lemmatisÃ© du corpus puis un Doc2Vec et un Word2Vec du corpus sans lemmatisation.
Le Word2Vec mean renvoie un vecteur moyen de chaque tweet. Lors de l' obtention des plongements, certaines manipulations ont dÃ» Ãªtre effectuÃ©es sur le corpus. En effet, en enlevant la ponctuation, les stop words et les emojis, il en rÃ©sultait des tweets vides. Il a Ã©tÃ© dÃ©cidÃ© de traiter cette erreur comme une exception Ã  lâ€™aide de lâ€™instruction tryâ€¦except dans notre code. AprÃ¨s ceci, on obtient les tweets qui comportent du contenu textuel.  

- Les Classifieurs

Pour les deux modÃ¨les de plongements lexicaux, nous avons fait des tests de classification binaire et multiclasse avec diffÃ©rents algorithmes de scikit-learn: kNN, SVM, Naive Bayes, Random Forest, RÃ©gression Logistique pour la classification binaire et kNN, SVM, Random Forest, RÃ©gression Logistique pour la classification multiclasse. 
Ce dossier prÃ©sentera par la suite chacun des modÃ¨les utilisÃ©s. Il sera explicitÃ© le schÃ©ma de code utilisÃ© pour utiliser les classifieurs, le modÃ¨le train et la partie test, et enfin les rÃ©sultats de la performance de nos classifieurs. On trouvera aussi le fonctionnement des rÃ©sultats obtenus selon le classifieur. On tente dâ€™expliquer la raison de ces rÃ©sultats selon lâ€™algorithme de chacun.

SVM
---
Le SVM est une technique d'apprentissage automatique qui trouve la meilleure sÃ©paration possible entre les classes. Le SVM trouve l'hyperplan qui maximise la marge de sÃ©paration entre les classes. Ces hyperplans sont appelÃ©s des kernels.
Les Kernels fonctionnent comme des fonctions qui transforment un espace de faible dimension en un espace de plus grande dimension. En dâ€™autres termes, ces fonctions quantifient la similaritÃ© entre deux observations dans un nouvel espace dimensionnel. Le modÃ¨le SVM admet plusieurs types de Kernels, nous avons limitÃ© nos essais Ã  deux types : polynomial et linÃ©aire.

Nous avons donc testÃ© la classification Ã  lâ€™aide de deux kernels diffÃ©rents, Il sâ€™est avÃ©rÃ© quâ€™en utilisant le premier la classification prenait trop de temps (2 Ã  3 fois plus de temps que le linÃ©aire). Certes, les rÃ©sultats Ã©taient lÃ©gÃ¨rement meilleurs avec le polynomiale mais pas assez pour justifier le temps Ã©coulÃ© pendant la classification. Il a Ã©tÃ© dÃ©cidÃ© de ne pas seulement faire la classification SVM linÃ©aire.
Les rÃ©sultats les plus parlant pour cet algorithme correspondent Ã  la classification US-UK (70%)  mÃªme si la diffÃ©rence entre la moyenne de l'exactitude tous algorithmes confondus (65%) nâ€™est pas Ã©norme, on peut toutefois affirmer que câ€™est notre meilleur rÃ©sultat de classification binaire.
Il est bien possible que lâ€™utilisation des dictionnaires ait influÃ© sur ce rÃ©sultat. Cependant, on a repÃ©rÃ© un phÃ©nomÃ¨ne dans la classification binaire et câ€™est quâ€™une des deux classes est mieux classÃ©e que lâ€™autre.Il a Ã©tÃ© rare de voir que les rÃ©sultats Ã©taient presque Ã©quilibrÃ©s entre deux classes. Cela pourrait Ãªtre dÃ» Ã  la nature de la tÃ¢che. En effet, sâ€™agissant de deux dialectes de la mÃªme langue leurs similitudes sont plus saillantes que leur diffÃ©rences ce qui va mettre en difficultÃ© lâ€™algorithme pour bien tracer la frontiÃ¨re entre les classes.  


K Nearest Neighbors
---
Ce classifieur est le moins performant sur lâ€™ensemble de nos tests, que ce soit la classification binaire ou multiclasse : presque avec toutes les reprÃ©sentations vectorielles et presque toutes les paires de dialectes, son accuracy est infÃ©rieure Ã  celles de la rÃ©gression logistique, SVM (mÃªme LinearSVC) et random forest. 
Nous pouvons pourtant remarquer que dans la classification multiclasse, ce classifieur fait des prÃ©dictions plus Ã©quilibrÃ©es (si on compare le nombre de prÃ©dictions correctes) entre les dialectes que les autres classifieurs. Câ€™est le seul classifieur qui sait distinguer â€˜UKâ€™ dans le cas de la classification multiclasse. Voici une idÃ©e des matrices de confusion obtenus, Ã  comparer pour la reprÃ©sentation de mean word2vec lemmatisÃ© et non : 
- RandomForestClassifier
- LogisticRegression
- KNeighborsClassifier
- LinearSVC

Logistic Regression
---
On tente aussi de donner notre dataset au classifieur de Logistic Regression. Bien sÃ»r, ce classifieur, comme tous les autres classifieurs, est sollicitÃ© pour le machine learning et notamment pour la classification selon 3 types :
- la classification binaire (binomial)
- la classification multiclasse (multinomiale)
- la classification dâ€™ordre (ordinale)
Dans notre cas, on applique ce classifieur pour une premiÃ¨re classification binaire. Ainsi, on tente de comparer certaines classes entre elles, et entre classifieurs. On dÃ©cide donc de comparer comme avec les autres classifieur les classes UK vs US. Les rÃ©sultats nous donneront un aperÃ§u de ce qui marche le mieux ou non entre classifieur, pour les mÃªmes classes sous Ã©tude. 

Pour la classification binaire entre les classe UK vs US, on voit que lâ€™accuracy est de 0.67 (soit 67,7%). Ce qui nâ€™est pas trop mal pour une premiÃ¨re lancÃ©e. Toutefois, cela reste loin dâ€™Ãªtre satisfaisant. 
Dâ€™autres combinaisons de langues ont Ã©tÃ© effectuÃ©es mais les rÃ©sultats nous paraissent biaisÃ©s pour de drÃ´le de raison. Câ€™est en effet toujours la classe Australia qui Ã©tait le mieux reconnue sachant que la classe AUS nâ€™avait pas de dictionnaire Ã  son bord puisque trop pauvre, et cette derniÃ¨re a lÃ©gÃ¨rement moins de donnÃ©es que les autres classes. ComparÃ© aux autres classifieurs, Logistic Regression nâ€™est pas le meilleur mais pas le pire non plus. En binaire, ce nâ€™est pas une catastrophe puisque lâ€™Ã©tiquette Y aura deux valeurs possibles 0 ou 1, soit Anglais = {0, 1}, respectivement 0 = UK et 1 = US. Dans ce cas de figure, câ€™est un peu comme le â€œpendantâ€ de la RÃ©gression LinÃ©aire qui est repris, oÃ¹ lâ€™on a que deux valeurs possibles (0 ou 1).

La classification de lâ€™anglais, en prenant compte de la fonction score, se fait donc dans cette logique ci (pour une classification binaire) :
- Cas 1)  Input > 0 , quand la classe (Ã©tiquette) vaut 1
- Cas 2) Input < 0, quand la classe (Ã©tiquette) vaut 0
La fonction score quâ€™on a obtenue intÃ¨gre les diffÃ©rentes variables prÃ©dictives. A cette fonction, on appliquera la fonction sigmoid (Sigmoid Function). Cette fonction produit des valeurs comprises entre 0 et 1. Dâ€™aprÃ¨s nos rÃ©sultats, câ€™est la classe UK qui est le mieux prÃ©dit dans notre cas. 
Etrangement, les rÃ©sultats sont meilleurs quand il nâ€™y a pas de lemmatisation des donnÃ©es. Il faut maintenant voir comment la classification sâ€™opÃ¨re pour du multiclasse.
On prend en compte cette fois-ci toutes nos classes, et on Ã©tend nos classifieurs Ã  du multiclass classification. On obtient donc les rÃ©sultats ci-dessous :

En multiclasse, les rÃ©sultats sont trÃ¨s bas, pour ne pas dire plutÃ´t mauvais. Logistic Regression nâ€™offre pas de bonne performance et cela est sans surprise puisque la rÃ©flexion qui se cache derriÃ¨re est celle-ci :
-Ã‰tape 1 : On considÃ¨re que lâ€™anglais UK est  la classe positive (Ã©tiquette 1) et le reste comme la classe nÃ©gative (dans ce cas, US, AUS et CA seront dans le mÃªme groupe de classe nÃ©gative (Ã©tiquette 0) ), et on entraÃ®ne la rÃ©gression logistique sur cette configuration de donnÃ©es. Ce qui  produira une fonction de prÃ©diction 
-Etape 2 : On considÃ¨re lâ€™anglais US comme la classe positive et le reste comme la classe nÃ©gative, et on entraÃ®ne la rÃ©gression logistique pour obtenir une deuxiÃ¨me fonction de prÃ©diction : 
-Etape 3 : On considÃ¨re lâ€™anglais CA comme la classe positive et le reste comme la classe nÃ©gative, et on entraÃ®ne la rÃ©gression logistique
De mÃªme, on considÃ¨re lâ€™anglais AUS comme positif et le reste comme nÃ©gatif, et on entraÃ®ne la rÃ©gression logistique dessus.
Toutes ces Ã©tapes nous permettent dâ€™Ã©tablir une probabilitÃ© que x input va Ãªtre dâ€™une classe Y. La bonne classe de lâ€™observation x est celle pour laquelle on a la plus grande probabilitÃ©. 

Random Forest 
---
Le classifieur Random Forest utilise des arbres de dÃ©cision et fonctionne par mÃ©thodes symboliques cherchant Ã  classer les donnÃ©es de celles qui sont les plus informatives ou les plus discriminantes pour ensuite Ã©valuer celles qui sont les moins diffÃ©rentes dans notre corpus.
Pour trouver les Ã©lÃ©ments les plus discriminants, l'algorithme Ã©value la diffÃ©rence ou l'homogÃ©nÃ©itÃ© d'une donnÃ©e en calculant la fonction Gini. Cette Ã©valuation se fait Ã©galement en utilisant des seuils dans le cas oÃ¹ un attribut ou une caractÃ©ristique parmi nos donnÃ©es n'est pas dÃ©finitif pour classer notre corpus.
Scikit learn nous permet d'utiliser l'algorithme avec certains paramÃ¨tres pour mieux rÃ©pondre Ã  notre tÃ¢che de classification. Les principaux paramÃ¨tres Ã  ajuster lors de son utilisation sont Â«n_estimatorsÂ» et Â« max_features Â» . Le premier est le nombre d'arbres dans la forÃªt. Normalement, plus il y a d'arbres, meilleure est la classification, mais plus le calcul est long. Â« n_estimators Â» est la taille des sous-ensembles alÃ©atoires de caractÃ©ristiques Ã  considÃ©rer lors de la division d'un nÅ“ud.
Nous avons tout d'abord testÃ© avec une profondeur maximale de 5 avec 300 estimateurs, ce qui n'a pas donnÃ© des rÃ©sultats idÃ©aux pour la classification multi-classe.  Nous avons pensÃ© que cela pouvait Ãªtre dÃ» Ã  un certain dÃ©sÃ©quilibre dans notre corpus. 
Selon la documentation de Scikit learn, les bonnes valeurs empiriques par dÃ©faut sont Â« max_features= sqrt Â» pour les tÃ¢ches de classification (oÃ¹ nombre des features est le nombre de caractÃ©ristiques dans les donnÃ©es). De bons rÃ©sultats sont souvent obtenus en dÃ©finissant Â«  max_depth=None  Â» en combinaison avec Â« min_samples_split=2 Â» . Nous avons Ã©galement essayÃ© ces paramÃ¨tres en fonction des consignes. Les valeurs par dÃ©faut donnent en effet de meilleurs rÃ©sultats que des paramÃ¨tres diffÃ©rents, notamment pour la classification binaire.
Dans la comparaison finale de tous les classifieurs, nous avons choisi les paramÃ¨tres par dÃ©faut de Random Forest.
En brefâ€¦

Conclusion et Perspective
---
Ce projet nous a permis de donner une premiÃ¨re base de la classification de dialecte qui peut Ãªtre reprise pour dâ€™autres langues et ses dialectes. Cette base se compose d'une mÃ©thodologie simple mais exploratoire en termes dâ€™hypothÃ¨ses. On reprend bien sÃ»r le prÃ©traitement, essentiel au bon traitement de notre corpus. Le nettoyage du corpus, qui comprend donc la suppression des stop words, les emojis, on essaie aussi la lemmatisation ou non, ce qui permet de voir les performances de nos classifieurs selon des donnÃ©es lemmatisÃ©es ou non lemmatisÃ©es. Par la suite, on lance les classifieurs selon une classification binaire ou multiclasse, parmi les algorithmes suivants : SVM, KNN, Logistic Regression, Random Forest. Les performances de chacun dâ€™entre eux sont plus ou moins Ã©quivalentes mais câ€™est SVM qui a les meilleurs rÃ©sultats malgrÃ© un temps de traitement extrÃªmement long. 

Dâ€™autres options de prÃ©traitement ont Ã©tÃ© envisagÃ©es et faites. On pourra notamment citer la lemmatisation de nos donnÃ©es avec Word2Vec et Doc2Vec, en plus des emojis gardÃ©s. Malheureusement les emojis nâ€™ont pas dâ€™impact suffisant pour jouer un rÃ´le dans la meilleure classification des donnÃ©es. Notre hypothÃ¨se dâ€™origine nâ€™est donc pas validÃ©e.

En revanche, il est vrai que dâ€™autres possibilitÃ©s pourraient Ãªtre ajoutÃ©es Ã  notre devoir pour la meilleure classification de dialectes. On pense notamment Ã  la prise en compte de lâ€™oral comme point dâ€™appuie et qui aiderait grandement Ã  la classification. Bien sÃ»r, cela engendre Ã©videmment des temps de rÃ©coltes du corpus plus consÃ©quent, puisque les donnÃ©es issues de lâ€™oral ne sont pas des plus propres. Prendre en compte la prosodie, le rythme, la phonologie de chaque dialecte auraient pu Ãªtre un poids dans le choix des classes pour une donnÃ©e.

Un autre point Ã  envisager serait de prendre en compte des mots spÃ©cifiques comme les link words - ou autre catÃ©gorie de mot comme les modaux et semi-modaux - et de regarder la rÃ©partition de chacun dâ€™entre eux. Le but Ã©tant de voir si un dialecte tend Ã  plus utiliser des linkwords que d'autres, et ainsi Ã©mettre un poids pour ces derniers. Une Ã©tude statistique grÃ¢ce aux techniques de linguistique de corpus et le langage R nous permettent de visualiser ceci. Cela pourrait Ãªtre un autre appuie Ã  des fins de classifications.

Enfin, la tÃ¢che fut un peu difficile en vue de notre choix de sujet et du corpus dont nous avions disposÃ©, mais elle fut enrichissante et pourrait Ãªtre poursuivie avec les suggestions que nous avons citÃ©es plus haut. Le dossier a Ã©tÃ© complÃ©tÃ© et nos hypothÃ¨ses et intuitions vÃ©rifiÃ©es, parfois confirmÃ©es, parfois non, mais câ€™Ã©tait un plaisir de le faire. On finira avec la conclusion suivante : lâ€™australien se distingue le plus de lâ€™anglais US qui lui-mÃªme se distingue de lâ€™anglais britannique. En revanche, lâ€™anglais US est trÃ¨s proche de lâ€™anglais canadien.
